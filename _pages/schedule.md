---
layout: page
title: Schedule
permalink: /schedule/
description: 
nav: true
nav_order: 3
horizontal: false
---

The workshop will be held in-person at ICML 2023 at the Hawaii
Convention Center on July 29th, 2023. Below is the
tentative outline for the workshop. All times are in Hawaii Standard Time (GMT-10):
<table id="conference-table">
  <tr>
    <th>Time</th>
    <th>Event</th>
    <th>Title</th>
    <th>Speaker</th>
  </tr>
  <tr>
  <td>9:00 - 9:30</td>
  <td>Opening Remarks</td>
  <td>Duality: An Overview</td>
  <td>Workshop Organizers</td> 
  </tr>
  <tr>
    <td>9:30 - 9:55</td>
    <td>Invited Talk</td>
	<td>Fenchel Duality Theory on Riemannian Manifolds and the
	Riemannian Chambolle-Pock Algorithm</td>
	<td><a href="https://ronnybergmann.net/">Ronny Bergmann</a></td>
  </tr>
  <tr>
    <td>9:55 - 10:05</td>
    <td colspan="3" style="text-align: center"> <b>Coffee break</b></td>
  </tr>
<tr>
    <td>10:05 - 10:17</td>
    <td>Contributed Talk</td>
	<td>Time-Reversed Dissipation Induces Duality Between Minimizing Gradient Norm and Function Value</td>
	<td>Jaeyeon Kim</td>
  </tr>
  <tr>
    <td>10:17 - 10:29</td>
    <td>Contributed Talk</td>
	<td>RIFLE: Imputation and Robust Inference from Low Order Marginals</td>
	<td>Sina Baharlouei</td>
  </tr>
  <tr>
    <td>10:30 - 10:42</td>
    <td>Contributed Talk</td>
	<td>A Representer Theorem for Vector-Valued Neural Networks: Insights on Weight Decay Training and Widths of Deep Neural Networks</td>
	<td>Joseph Shenouda</td>
  </tr>
  <tr>
    <td>10:45 - 11:10</td>
    <td>Invited Talk</td>
	<td>Duality for Neural Networks through Reproducing Kernel Banach Spaces</td>
	<td> <a href="https://people.utwente.nl/l.spek"> Len Spek </a> </td>
  </tr>
  <tr>
    <td>11:10 - 11:35</td>
    <td>Invited Talk</td>
	<td>Convergence of mean field Langevin dynamics: Duality viewpoint and
neural network optimization</td>
	<td> <a href="http://ibis.t.u-tokyo.ac.jp/suzuki/"> Taiji Suzuki </a> </td>
	</tr>
<tr>
    <td>11:35 - 12:00</td>
    <td>Invited Talk</td>
	<td>Duality from Gradient Flow Force-Balance to Distributionally
	Robust Learning</td>
	<td><a href="https://jj-zhu.github.io/">Jia-Jie Zhu</a></td>
  </tr>
  <tr>
    <td>12:00 - 13:00</td>
    <td colspan="3" style="text-align: center"> <b>Lunch</b></td>
  </tr>
  <tr>
    <td>13:00 - 14:30</td>
    <td colspan="3" style="text-align: center"> <b>Poster Session</b></td>
  </tr>
<tr>
    <td>14:30 - 14:55</td>
    <td>Invited Talk</td>
	<td>Dual RL: Unification and New Methods for Reinforcement and Imitation Learning</td>
	<td> <a href="https://amyzhang.github.io"> Amy Zhang </a> </td>
  </tr>
<tr>
    <td>14:55 - 15:35</td>
    <td colspan="3" style="text-align: center"> <b>Coffee Break &
	Poster Session</b></td>
  </tr>
  <tr>
    <td>15:35 - 16:00</td>
    <td>Invited Talk</td>
	<td>A Dualistic View of Activations in Deep Neural Networks</td>
	<td> <a href="https://sites.google.com/view/eamid/"> Ehsan Amid </a> </td>
  </tr>
  <tr>
    <td>16:00 - 17:00</td>
	<td>Panel Discussion</td>
	<td>Duality in Modern Machine Learning</td>
	<td>Speakers & Organizers</td>
  </tr>
</table>

<br>
<br>

List of accepted papers:
<table id="conference-table">
  <thead>
    <tr>
      <th>Paper Title</th>
      <th>Authors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://arxiv.org/abs/2305.06628">Time-Reversed Dissipation Induces Duality Between Minimizing Gradient Norm and Function Value</a></td>
      <td>Jaeyeon Kim, Asuman E. Ozdaglar, Chanwoo Park, Ernest K. Ryu</td>
    </tr>
    <tr>
      <td><a href="https://arxiv.org/abs/2305.15249"> Decision-Aware Actor-Critic with Function Approximation and Theoretical Guarantees</a></td>
      <td>Sharan Vaswani, Amirreza Kazemi, Reza Babanezhad Harikandeh, Nicolas Le Roux</td>
    </tr>
    <tr>
      <td><a href="/assets/pdf/ThePowerOfDuality.pdf">The Power of Duality Principle in Offline Average-Reward Reinforcement Learning</a></td>
      <td>Asuman E. Ozdaglar, Sarath Pattathil, Jiawei Zhang, Kaiqing Zhang</td>
    </tr>
    <tr>
      <td>Reward-Based Reinforcement Learning with Risk Constraints</td>
      <td>Jane Lee, Konstantinos Nikolakakis, Dionysios Kalogerias, Amin Karbasi</td>
    </tr>
    <tr>
      <td><a href="https://arxiv.org/abs/2307.09602"> A max-affine spline approximation of neural networks using the Legendre transform of a convex-concave representation</a></td>
      <td>Adam Perrett, Danny Wood, Gavin Brown</td>
    </tr>
    <tr>
      <td>Duality Principle and Biologically Plausible Learning: Connecting the Representer Theorem and Hebbian Learning</td>
      <td>Yanis Bahroun, Dmitri Chklovskii, Anirvan M. Sengupta</td>
    </tr>
    <tr>
      <td><a href="/assets/pdf/fisher.pdf">On the Fisher-Rao Gradient of the Evidence Lower Bound</a></td>
      <td>Jesse van Oostrum, Nihat Ay</td>
    </tr>
    <tr>
      <td><a href="http://www.sonnyachten.com/dMVRKM/"> Duality in
	  Multi-View Restricted Kernel Machines </a></td>
      <td>Sonny Achten, Arun Pandey, Hannes De Meulemeester, Bart De Moor, Johan Suykens</td>
    </tr>
    <tr>
      <td><a href=" https://hdeplaen.github.io/kppca"> A Dual
	  Formulation for Probabilistic Principal Component Analysis </a></td>
      <td>Henri De Plaen, Johan Suykens</td>
    </tr>
    <tr>
      <td>Energy-Based Non-Negative Tensor Factorization via Multi-Body Modeling</td>
      <td>Kazu Ghalamkari, Mahito Sugiyama</td>
    </tr>
    <tr>
      <td>Dual Gauss-Newton Directions for Deep Learning</td>
      <td>Vincent Roulet, Mathieu Blondel</td>
    </tr>
    <tr>
      <td>Controlling the Inductive Bias of Wide Neural Networks by Modifying the Kernel's Spectrum</td>
      <td>Amnon Geifman, Daniel Barzilai, Ronen Basri, Meirav Galun</td>
    </tr>
    <tr>
      <td>Kernel Mirror Prox and RKHS Gradient Flow for Mixed Functional Nash Equilibrium</td>
      <td>Pavel Dvurechensky, Jia-Jie Zhu</td>
      </tr>
	   <tr>
    <td>A Representer Theorem for Vector-Valued Neural Networks: Insights on Weight Decay Training and Widths of Deep Neural Networks</td>
    <td>Joseph Shenouda, Rahul Parhi, Kangwook Lee, Robert D Nowak</td>
  </tr>
  <tr>
    <td><a href="/assets/pdf/RIFLE_Duality.pdf">RIFLE: Imputation and Robust Inference from Low Order Marginals</a></td>
    <td>Sina Baharlouei, Kelechi Ogudu, Peng Dai, Sze-chuan Suen, Meisam Razaviyayn</td>
  </tr>
  <tr>
    <td>Estimating Joint interventional distributions from marginal interventional data</td>
    <td>Sergio Hernan Garrido Mejia, Elke Kirschbaum, Armin Kekić, Atalanti A. Mastakouri</td>
  </tr>
  <tr>
    <td><a href="/assets/pdf/learning_primal_dual_srm_camera_ready.pdf">Learning with Primal-Dual Spectral Risk Measures: a Fast Incremental Algorithm</a></td>
    <td>Ronak Mehta, Vincent Roulet, Krishna Pillutla, Zaid Harchaoui</td>
  </tr>
  <tr>
    <td>Implicit Interpretation of Importance Weight Aware Updates</td>
    <td>Keyi Chen, Francesco Orabona</td>
  </tr>
  <tr>
    <td>The Memory-Perturbation Equation: Understanding Model's Sensitivity to Data</td>
    <td>Peter Nickl, Lu Xu, Dharmesh Tailor, Thomas Möllenhoff, Mohammad Emtiyaz Khan</td>
  </tr>
  <tr>
    <td>Memory Maps to Understand Models</td>
    <td>Dharmesh Tailor, Paul Edmund Chang, Siddharth Swaroop, Eric Nalisnick, Arno Solin, Mohammad Emtiyaz Khan</td>
  </tr>
  <tr>
    <td>Sparse Function-Space Representation of Neural Networks</td>
    <td>Aidan Scannell, Riccardo Mereu, Paul Edmund Chang, Ella Tamir, Joni Pajarinen, Arno Solin</td>
  </tr>
	  </tbody>
	  </table>

